{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QPf9NjSh5K7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1: Написать код для вычисления tf для заданного слова и главы из текста. Рассчитать tf для всех слов и каждой главы. Результаты сохраняются в виде словаря."
      ],
      "metadata": {
        "id": "Uk7EFxDPvb_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Продублируем часть кода из задания\n",
        "\n",
        "# Преобразуем текстовый файл в список\n",
        "\n",
        "# Импортируем библиотеку для выполнения HTTP-запросов в интернет\n",
        "import requests\n",
        "# Читаем текстовый файл по url-ссылке\n",
        "data = requests.get(\"https://raw.githubusercontent.com/SkillfactoryDS/Datasets/master/war_peace_processed.txt\").text\n",
        "# Предобрабатываем текстовый файл\n",
        "data = data.split('\\n')\n",
        "data.remove('')\n",
        "data = data + ['[new chapter]']\n",
        "\n",
        "# Создаем список по главам со списками слов в каждой главе\n",
        "\n",
        "# Инициализируем общий список, в котором будем хранить списки слов в каждой главе\n",
        "chapter_data = []\n",
        "# Инициализируем список слов, в котором будет хранить слова одной главы\n",
        "chapter_words = []\n",
        "\n",
        "# Создаем цикл по всем словам из списка\n",
        "for word in data:\n",
        "    # Проверяем, что текущее слово - обозначение новой главы\n",
        "    if word == '[new chapter]':\n",
        "        # Если условие выполняется, добавляем список со словами из главы в общий список\n",
        "        chapter_data.append(chapter_words)\n",
        "        # Обновляем (перезаписываем) список со словами из текущей главы\n",
        "        chapter_words = []\n",
        "    else:\n",
        "        # В противном случае, добавляем текущее слово в список со словами из главы\n",
        "        chapter_words.append(word)"
      ],
      "metadata": {
        "id": "CJK9lyPK5oQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vPJs_czdvUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Превращаем список в множество, удаляя дублирующиеся слова\n",
        "word_set = set(data)\n",
        "# Удаляем из множества слово, символизирующее раздел между главами\n",
        "word_set.discard('[new chapter]')\n",
        "# Выводим результаты\n",
        "print('Общее количество слов: {}'.format(len(data)))\n",
        "print('Общее количество уникальных слов: {}'.format(len(word_set)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPNZVk27wkpM",
        "outputId": "9fa4e1e7-3be8-49c7-aa05-38570d2e6d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общее количество слов: 300080\n",
            "Общее количество уникальных слов: 38210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализируем пустой словарь\n",
        "word_counts = {}\n",
        "# Инициализируем количество глав\n",
        "count_chapter = 0\n",
        "# Создаем цикл по всем словам из списка слов\n",
        "for word in data:\n",
        "    # Проверяем, что текущее слово - обозначение новой главы\n",
        "    if word == '[new chapter]':\n",
        "        # Если условие выполняется, то увеличиваем количество глав на 1\n",
        "        count_chapter += 1\n",
        "        # Переходим на новую итерацию цикла\n",
        "        continue\n",
        "    # Проверяем, что текущего слова еще нет в словаре слов\n",
        "    if word not in word_counts:\n",
        "        # Если условие выполняется, инициализируем новый ключ 1\n",
        "        word_counts[word] = 1\n",
        "    else:\n",
        "        # В противном случае, увеличиваем количество слов на 1\n",
        "        word_counts[word] += 1"
      ],
      "metadata": {
        "id": "HavhdiEMxEVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Дублирую из задания код создания списка словарей по главам: в словаре слову соответстует - число повторов этого слова в главе\n",
        "\n",
        "# Инициализируем список, в котором будем хранить словари\n",
        "chapter_words_count = []\n",
        "\n",
        "# Создаем цикл по элементам внешнего списка со словами\n",
        "for chapter_words in chapter_data:\n",
        "    # Инициализируем пустой словарь, куда будем добавлять результаты\n",
        "    temp = {}\n",
        "    # Создаем цикл по элементам внутреннего списка\n",
        "    for word in chapter_words:\n",
        "        # Проверяем, что текущего слова еще нет в словаре\n",
        "        if word not in temp:\n",
        "            # Если условие выполняется, добавляем ключ в словарь\n",
        "            temp[word] = 1\n",
        "        else:\n",
        "            # В противном случае, увеличиваем количество влождений слова в главу\n",
        "            temp[word] += 1\n",
        "    # Добавляем получившийся словарь в список\n",
        "    chapter_words_count.append(temp)"
      ],
      "metadata": {
        "id": "RMsk4PhqB7AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Найдем частоту слова гостья в 15 - й главе\n",
        "get_word = 'гостья'\n",
        "target_chapter = 15\n",
        "\n",
        "# Пишем код для вычисления показателя tf\n",
        "# Сколько раз слово встречается в главе мы можем получить по запросу из списка chapter_words_count\n",
        "# Число уникальных слов в главе - берем из длины списка в в списках chapter_data по главам - это число уникальных слов в заданной слове.\n",
        "tf=chapter_words_count[target_chapter].get(get_word)/len(chapter_data[target_chapter])\n",
        "\n",
        "print(f'Частота употребления слова \"{get_word}\" в главе {target_chapter} - {round(tf*100,4)} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAlr_2EmC4Be",
        "outputId": "53715f4b-7202-4262-9f2b-7351b484d6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Частота употребления слова \"гостья\" в главе 15 - 0.7358 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь рассчитаем показатель Tf для каждого слова в каждой главе и запишем результаты в структуру chapter_words_tf - список словарей по главам, где в каждом словаре слову из главы соответствует показатель Tf. После чего - можно получать результат обращаясь к списку chapter_words_tf по заданным \"слову\" и \"главе\"."
      ],
      "metadata": {
        "id": "4f_6UVWgUqnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_word = 'гостья'\n",
        "target_chapter = 15\n",
        "\n",
        "# Создаем пустой список\n",
        "chapter_words_tf = []\n",
        "\n",
        "# Запрускаем цикл по элементам списка словарей chapter_words_count\n",
        "for chapter_number, chapter_dict in enumerate(chapter_words_count):\n",
        "  # Создаем в цикле пустой словарь.\n",
        "  temp_dict={}\n",
        "  # Запускаем в цикле по текущему словарю цикл по его элементам (для корректности кода используем функцию items по работе со словарями, в результате чего текущий словарь преобразуется в кортеж)\n",
        "  for words, counts in chapter_dict.items():\n",
        "    # Во внутреннем цикле в словарь temp_dict заносим по новому ключу(текущее слово) - значение показателя tf для этого слова в текущей главе.\n",
        "    temp_dict[words]=counts/len(chapter_data[chapter_number])\n",
        "  # Пролистав все уникальные слова в главе - в список chapter_words_tf заносим текущий словарь с рассчитанными для каждого уникального слова значениями tf\n",
        "  chapter_words_tf.append(temp_dict)\n",
        "\n",
        "# Делаем запрос к созданной структуре chapter_words_tf по заданному слову и главе\n",
        "tf=chapter_words_tf[target_chapter].get(get_word)\n",
        "print(f'Частота употребления слова \"{get_word}\" в главе {target_chapter} - {round(tf*100,4)} %')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkGysQkp0IMw",
        "outputId": "f1efef58-abf0-4789-d394-bc5075fc1678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Частота употребления слова \"гостья\" в главе 15 - 0.7358 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2. Нужно рассчитать для заданного слова показатенль df - частоту упоминания слова по главам."
      ],
      "metadata": {
        "id": "pkAcdtVoqv43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_word = 'человек'\n",
        "\n",
        "n=0  # В переменной n мы будем считать колличество вхождений заданного слова в главы книги\n",
        "for i in range(0,count_chapter): # Запускаем цикл по главам книги\n",
        "  if target_word in chapter_data[i]: # Проверяем вхождение слова в текущую главу\n",
        "    n+=1 # В случае вхождения слова в текущую главу увеличиваем счетчик на 1-цу\n",
        "\n",
        "df=n/count_chapter # Рассчитываем показатель df для заданного слова путем деления значения переменной n на число глав\n",
        "\n",
        "print(f'Частота упоминания \"{target_word}\" по главам в книге составляет - {round(df*100,4)} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIaRJKJDq1rg",
        "outputId": "8be083b4-32b6-4b42-8315-3a382a5ebeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Частота упоминания \"человек\" по главам в книге составляет - 67.2515 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь рассчитаем показатель df для каждого уникального слова из книги и результаты занесем в словарь df_words, где каждому слову будет  соотвествовать его показатель df. После этого - можно получать результат обращаясь в словарь df_words по ключу - слову."
      ],
      "metadata": {
        "id": "88FNAcB5QpW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_words={} # Создаем пустой словарь\n",
        "\n",
        "for words in word_set: # Запускаем цикл по уникальным словам книги.\n",
        "  n=0 # В переменной n будем считать число вхождений текущего слова в главы книги\n",
        "  for i in range(0,count_chapter): # Запускаем для текущего уникального слова цикл по главам книги\n",
        "    if words in chapter_data[i]: # Прорверяем вхождение слова в текущую главу\n",
        "      n+=1 # В случае положительного результата увеличиваем значения счетчика n\n",
        "  df=n/count_chapter # Считаем  показатель df для уникального слова из книги\n",
        "  df_words[words]=df # Заносим в словарь df_words по ключу-слово соответствующий ему показатель df"
      ],
      "metadata": {
        "id": "v0ARwTwByajM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_word = 'человек'\n",
        "\n",
        "print(f'Частота упоминания \"{target_word}\" по главам в книге составляет - {round(df_words[target_word]*100,4)} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EXEBENz0var",
        "outputId": "f6e37bec-639a-4049-ce91-3bedc7b75f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Частота упоминания \"человек\" по главам в книге составляет - 67.2515 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 3. Теперь для заданного слова и главы рассчитываем показатель - td_idf."
      ],
      "metadata": {
        "id": "qQhF4ZcpRuhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_word = 'анна'\n",
        "target_chapter = 4\n",
        "\n",
        "from math import log\n",
        "# Рассчитываем показатель td_idf путем запроса к структурам chapter_words_tf и df_words\n",
        "td_idf=chapter_words_tf[target_chapter][target_word]*log(1/df_words[target_word])\n",
        "\n",
        "print(f'Контрастность \"{target_word}\" в главе {target_chapter} - {round(td_idf,6)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCcYUCjk1_p7",
        "outputId": "dc34b872-aa37-49fe-f4bb-5b257371058e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Контрастность \"анна\" в главе 4 - 0.011067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассчитываем теперь показатель td_idf для каждого слова в каждой главе и результаты записываем в список словарей по главам chapter_words_td_idf, где каждому слову в словаре будет соответствовать показатель td_idf. Теперь искомый показатель можно будет получать из этой структуры по запросу - \"слово\" и \"глава\"."
      ],
      "metadata": {
        "id": "A7B8f4D-SCqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chapter_words_td_idf = [] # Создаем пустой список\n",
        "\n",
        "from math import log\n",
        "\n",
        "for chapter_number, chapter_dict in enumerate(chapter_words_tf): # Запускаем цикл по элементам списка chapter_words_tf - главы и соответствующие им словари: слово - показатель tf\n",
        "  temp_dict={} # Создаем пустой словарь\n",
        "  for words, counts in chapter_dict.items(): # Запускаем цикл по текущему словарю соответствующему текущей главе\n",
        "    temp_dict[words]=chapter_words_tf[chapter_number][words]*log(1/df_words[words]) # Рассчитываем для текущего слова показатель td_idf и заносим его в словарь\n",
        "  chapter_words_td_idf.append(temp_dict) # Пролистав слова в текущей главе - заносим словарь с рассчитанными td_idf по уникальным словам в главе"
      ],
      "metadata": {
        "id": "v2AAlXUO5JL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_word = 'анна'\n",
        "target_chapter = 4\n",
        "\n",
        "td_idf=chapter_words_td_idf[target_chapter].get(target_word) # Получаем td_idf для заданного слова и главы путем запроса к структуре chapter_words_td_idf\n",
        "print(f'Контрастность \"{target_word}\" в главе {target_chapter} - {round(td_idf,6)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtn3DDlA7ye3",
        "outputId": "7da80648-9d95-4b6c-f45e-44fe013eed90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Контрастность \"анна\" в главе 4 - 0.011067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 4. Теперь нужно найти по заданной в запросе главе - тройку самых значимых (контракстных) слов в этой главе и распечатать результат."
      ],
      "metadata": {
        "id": "XihZv3dmS6_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_chapter = 3\n",
        "\n",
        "# Создаем кортеж sorted_words заносим отсортированныйе по убыванию элементы словаря, соответствующий заданной главе, из структуры chapter_words_td_idf.\n",
        "sorted_words=sorted(chapter_words_td_idf[target_chapter].items(), reverse=True, key=lambda item: item[1])\n",
        "\n",
        "# Печатаем из первых трех элементов кортежа sorted_words - первые элементы - соответствующие трем первым значимым словам главы.\n",
        "K=0\n",
        "for i in sorted_words:\n",
        "  K+=1\n",
        "  if K==4:\n",
        "    break\n",
        "  print(i[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1K5LhKA9KpW",
        "outputId": "a60b1597-967a-4370-b722-14957fa873a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "павловна\n",
            "анна\n",
            "функе\n"
          ]
        }
      ]
    }
  ]
}